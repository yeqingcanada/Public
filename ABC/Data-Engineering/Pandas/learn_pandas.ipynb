{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e80589",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# https://www.youtube.com/watch?v=ZyhVh-qRZPA&list=PL-osiE80TeTsWmV9i9c58mdDCSskIFdDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c558e40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. getting started\n",
    "\n",
    "df = pd.read_csv('data/survey_results_public.csv')\n",
    "schema_df = pd.read_csv('data/survey_results_schema.csv')\n",
    "\n",
    "df.shape                                        # shape返回（行数，列数）\n",
    "df.info()                                       # info（）返回每列信息：列名，非空行数，数据结构\n",
    "df.columns                                      # columns 返回列名, 回值是一个Pandas Index对象。Index对象是一个不可变的数组：Index(['Name', 'Age', 'City'], dtype='object')\n",
    "pd.set_option('display.max_columns', 85)        # Pandas显示时能够显示的最大列数为85\n",
    "pd.set_option('display.max_rows', 85)\n",
    "schema_df.head(10)                              # df.head() 默认情况下它将返回前5行数据\n",
    "\n",
    "df\n",
    "schema_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c243972",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. dataframe and series basic\n",
    "\n",
    "people = {\n",
    "    \"first\": [\"Corey\", 'Jane', 'John', 'Adam'],\n",
    "    \"last\": [\"Schafer\", 'Doe', 'Doe', 'Doe'],\n",
    "    \"email\":[\"CoreyMSchafer@gmail.com\", 'JaneDoe@email.com', 'JohnDeo@email.com', 'A@gmail.com'],\n",
    "#     'age': [1,2,3],\n",
    "#     'income':[1.2,2.2,3.3]\n",
    "}\n",
    "df = pd.DataFrame(people)\n",
    "df\n",
    "\n",
    "df['email']                         # 结果是一个series，包含了email这一列的所有item\n",
    "type(df['email'])                   # pandas.core.series.Series\n",
    "df[['email', 'last']]               # 只包含这两列\n",
    "df.columns\n",
    "df.iloc[[0,1],[0,1]]                # 第一个参数[0,1]是行，第二个参数[0,1]是列，第一个array是指取index是0-1的行，第二个array是指取index0-1的列\n",
    "df.loc[[0,1],['email', 'last']]     # loc: label, iloc:location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44aef52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. dataframe and series basic\n",
    "# data is from 'data/survey_results_public.csv'\n",
    "\n",
    "df['Hobbyist'].value_counts()                 # 形成一个series，index是Hobbyist的不同值，内容是这些值的count结果\n",
    "                                              # 一般series，index以0开始，内容是值，类似list\n",
    "df.loc[0:2,'Hobbyist':'Employment']           # 取行index0-2，列从'Hobbyist'到'Employment'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66f178a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. index\n",
    "\n",
    "import pandas as pd\n",
    "people = {\n",
    "    \"first\": [\"Corey\", 'Jane', 'John', 'Adam'],\n",
    "    \"last\": [\"Schafer\", 'Doe', 'Doe', 'Doe'],\n",
    "    \"email\":[\"CoreyMSchafer@gmail.com\", 'JaneDoe@email.com', 'JohnDeo@email.com', 'A@gmail.com']\n",
    "}\n",
    "df = pd.DataFrame(people)\n",
    "\n",
    "df.set_index('email')                          # 不改变原有dataframe，index原始的index，0-3\n",
    "print(\"df\", df)\n",
    "print('df.index', df.index)\n",
    "# ------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "df.set_index('email', inplace=True)            # 确实改变原dataframe，index变成email\n",
    "print(\"df\", df)\n",
    "print(\"df.index\", df.index)\n",
    "df.loc['CoreyMSchafer@gmail.com']              # 有了index后，可以利用其定位，没有index之前，只能利用数字定位\n",
    "# ------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "df.reset_index(inplace=True)                   # index设置变回初始值，每次重复执行这句，都会多出一列‘index’ 。最多只能重复一次                \n",
    "print('df', df)\n",
    "df.reset_index(inplace=True)                   \n",
    "print('df', df) \n",
    "df.reset_index(inplace=True)                   \n",
    "print('df', df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609fb3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. index\n",
    "# data is from data/survey_results_public.csv & data/survey_results_schema.csv\n",
    "\n",
    "# ------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "df = pd.read_csv('data/survey_results_public.csv', index_col='Respondent')  # 读入时直接将Respondent设置为index\n",
    "df.head()\n",
    "# ------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "schema_df = pd.read_csv('data/survey_results_schema.csv', index_col='Column')\n",
    "schema_df.sort_index(ascending=False, inplace=True)         # 如果不添加 inplace=True，默认情况下结果不会直接修改原对象，而是返回一个新的对象\n",
    "print(\"schema_df\", schema_df)\n",
    "schema_df.sort_index(ascending=True, inplace=True)\n",
    "print(\"schema_df\", schema_df)\n",
    "result = schema_df.loc['MgrIdiot', 'QuestionText']          # 第一个参数是行，取‘Column’（这列是index列，上一步中设置的）\n",
    "                                                            #（Column是列的名字）这列值为‘MgrIdiot’的行\n",
    "                                                            # 第二个参数是列，再取‘QuestionText’（这是列的名字）这列\n",
    "print(\"result\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a28e607",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. filtering\n",
    "# data is from people\n",
    "\n",
    "filt = df['last'] == 'Doe'\n",
    "df[filt]                            # 传入series of boolean，返回true的行\n",
    "df.loc[filt]                        # 与上一行效果一样，传入series of boolean，返回true的行\n",
    "df.loc[filt, ['email', 'last']]     # 可以定位某行某列         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3be7c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. filtering\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('data/survey_results_public.csv')\n",
    "# ------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "counties = ['United States', 'India', 'United Kingdom', 'Germany', 'Canada']\n",
    "filt = df['Country'].isin(counties)\n",
    "df.loc[filt, 'Country']\n",
    "# ------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "filt = df['LanguageWorkedWith'].str.contains('Python', na=False)       # na等于false意味着不处理na这种情况，是为了避免na报错\n",
    "df.loc[filt, 'LanguageWorkedWith']                                     # retrieves the values from the 'LanguageWorkedWith' column of df where the filt condition is True. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9620b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Updating Rows and Columns\n",
    "# data is from people\n",
    "\n",
    "# ------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "# update columns\n",
    "df.columns                                                                      # ['first', 'last', 'email', 'age', 'income']\n",
    "df.columns = ['first_name', 'last_name', 'email', 'age', 'income']              # change the column name in df\n",
    "df.columns = [x.upper() for x in df.columns]\n",
    "df.columns = df.columns.str.replace(' ','_')\n",
    "df.columns = [x.lower() for x in df.columns]\n",
    "# 改变列的名字\n",
    "df = df.rename(columns={'first_name': 'first', 'last_name': 'last'})            # 需要再写一遍df=df...才会改变\n",
    "df.rename(columns={'first_name': 'first', 'last_name': 'last'}, inplace=True)   # 或者inplace为true\n",
    "# ------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "# update rows\n",
    "df.loc[2] = ['John', 'Smith', 'JohnSmith@email.com']           # 更新index是2的这行的信息\n",
    "df.loc[2, ['last', 'email']] = ['Deo', 'JohnDeo@email.com']    # 可以只更新两列\n",
    "# ------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "filt = (df['email'] =='JohnDeo@email.com')\n",
    "###### df[filt]['last'] = 'Smith'                               # 这样写是错误的，这是一个copy temp，不能改变原有df            \n",
    "df.loc[filt, 'last'] = 'Smith'                                  # 这样写才可以确实改变df\n",
    "# ------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "df['email'] = df['email'].str.lower()\n",
    "# ------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "# apply: apply在series上，作用在series的每个值上；apply在dataframe上，作用在每个series上\n",
    "df['email'].apply(len)                              # 返回每个email的长度, 返回值是一个Series \n",
    "df.apply(len)                                       # 返回每个series的长度，first-3，last-3，email-3\n",
    "df.apply(len, axis='columns')                       # axis='rows' 是 default, 返回每列有几行， axis='columns' 返回每行有几列0-3，1-3，2-3，3-3         \n",
    "def update_email(email):\n",
    "    return email.upper()\n",
    "df['email'] = df['email'].apply(update_email)\n",
    "df['email'] = df['email'].apply(lambda x: x.lower())\n",
    "df.apply(pd.Series.min)                             # 返回字母表顺序最小的一个值，first-Corey,last-Doe,email-core...\n",
    "df.apply(lambda x: x.min())                         # 同above的结果\n",
    "# ------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "# applymap: 只作用在dataframe上，改变每一个individual的值\n",
    "df.applymap(len)                                    # applymap 不支持 inplace=True，必须将返回值赋给另一个variable result = df.applymap(len)   \n",
    "df.applymap(str.lower)\n",
    "# 带括号 () 的函数实际上称为此函数 , 而不带括号 () 的函数是此函数的对象, 可用作参数传输\n",
    "# ------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "# map\n",
    "# 作用在series上，substituting each value in a series with another value\n",
    "df['first'].map({'Corey':'Chris', 'Jane':'Mary'})                       # 没被指定的John会变成 NaN，为了避免这个问题，应该使用replace\n",
    "# ------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "# replace\n",
    "df['first'] = df['first'].replace({'Corey':'Chris', 'Jane':'Mary'})     # 这个方法没有replace为true的设置，只能用等于改变原df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e197ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Updating Rows and Columns - TEST\n",
    "import pandas as pd\n",
    "people = {\n",
    "    \"first\": [\"Corey\", 'Jane', 'John', 'Adam'],\n",
    "    \"last\": [\"Schafer\", 'Doe', 'Doe', 'Doe'],\n",
    "    \"email\":[\"CoreyMSchafer@gmail.com\", 'JaneDoe@email.com', 'JohnDeo@email.com', 'A@gmail.com']\n",
    "}\n",
    "df = pd.DataFrame(people)\n",
    "\n",
    "df.applymap(len, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495de114",
   "metadata": {},
   "source": [
    "### 可以使用 inplace=True 的方法\n",
    "    \n",
    "DataFrame.drop(): 删除行或列。  \n",
    "DataFrame.drop_duplicates(): 删除重复的行。  \n",
    "DataFrame.rename(): 重命名索引或列名。  \n",
    "DataFrame.reset_index(): 重置索引。  \n",
    "DataFrame.set_index(): 设置索引。  \n",
    "DataFrame.sort_index(): 按索引排序。  \n",
    "DataFrame.sort_values(): 按列值排序。  \n",
    "DataFrame.fillna(): 填充缺失值。  \n",
    "DataFrame.replace(): 替换值。  \n",
    "Series.sort_index(): 对Series的索引进行排序。  \n",
    "Series.sort_values(): 对Series的值进行排序。  \n",
    "Series.drop(): 删除Series中的项。  \n",
    "Series.drop_duplicates(): 删除Series中的重复项。  \n",
    "DataFrame.pivot_table(): 生成数据透视表时，虽然不直接支持inplace，但可以通过赋值操作来更新原DataFrame。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589502ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Add/Remove Rows and Columns\n",
    "# data is from people\n",
    "\n",
    "# ------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "# add new column\n",
    "df['full_name'] = df['first'] + ' ' + df['last']\n",
    "# delete columns\n",
    "df.drop(columns=['first', 'last'], inplace=True)\n",
    "# 写等式效果同inplace=True\n",
    "df = df.drop(columns=['first', 'last'])\n",
    "# splite full_name column into two columns, 如果不加expand为true，则full_name会变为一个二元数组，加了这个，则df会新增两列\n",
    "df[['first', 'last']]=df['full_name'].str.split(' ', expand=True)\n",
    "# ------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "# 添加新的一行。如果不加这句ignore_index=True，会报错，因为这个df没有index\n",
    "df.append({'first':'Tony'}, ignore_index=True)\n",
    "# 将一个df append到另一个df上\n",
    "people = {\n",
    "    \"first\": [\"Tony\", 'Steven'],\n",
    "    \"last\": [\"Stark\", 'Rogers'],\n",
    "    \"email\":[\"IronMan@gmail.com\", 'Cap@email.com']\n",
    "}\n",
    "df2 = pd.DataFrame(people)\n",
    "df.append(df2,ignore_index=True, sort=False)\n",
    "# ------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "# delete row\n",
    "df.drop(index=4)\n",
    "# delete last等于Doe的行\n",
    "filt = df['last'] == 'Doe'\n",
    "df.drop(index=df[filt].index)\n",
    "# ------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "# 将原始DataFrame的前四列保持位置不变，将原来的最后一列移动到前四列之后，然后是第五列到第十一列的数据，如果原DataFrame列数超过了12列，那么超过的部分将不会包含在新的DataFrame中。\n",
    "cols = list(df.columns)\n",
    "df = df[cols[0:4] + [cols[-1]] + cols[4:12]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a48ea9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Sorting Data\n",
    "# data is from people\n",
    "\n",
    "# ------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "# 先按last的降序排列，在此基础上，按first的升序排列\n",
    "df.sort_values(by=['last','first'], ascending=[False,True], inplace=True)\n",
    "# 在上面的基础上，想要恢复原状。上面一句结束以后，index是乱序的。\n",
    "df.sort_index()\n",
    "# 只是想简单的sort一列，返回一个serias\n",
    "df['last'].sort_values()\n",
    "# ------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "# data is from data/survey_results_public.csv\n",
    "# 针对一个列，返回最大的10个值。两种写法都可以，第一种返回一个serias，第二种返回10行原始df\n",
    "df['ConvertedComp'].nlargest(10)\n",
    "df.nlargest(10, 'ConvertedComp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf97c048",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Grouping and Aggregating - Analyzing and Exploring Your Data\n",
    "import pandas as pd\n",
    "df = pd.read_csv('data/survey_results_public.csv')\n",
    "# ------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "# 一些常用的数据分析方法，查看数据的各种属性\n",
    "df['ConvertedComp'].head(10)                            # 返回值是一个serias，包含ConvertedComp的前10列\n",
    "df['ConvertedComp'].median()                            # 中位数\n",
    "df.median()                                             # 数值列的中位数，返回值是一个 Serias 对象。Series的索引是原DataFrame中数值列的列名，每个索引对应的值是该列的中位数\n",
    "df.describe()                                           # 每一个列的 count: not na rows, mean, std: 标准差, min, 25%, 50%: 中位数, 75%, max\n",
    "df['ConvertedComp'].count()                             # 与上面一句的结果中的，count，一致。非空的行数\n",
    "df['SocialMedia'].value_counts()                        # 这一列中不同的值，以及他们的count\n",
    "df['SocialMedia'].value_counts(normalize=True)          # 这一列中不同的值，以及他们所占的百分比\n",
    "# ------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "# 利用 filter 演示，方便理解 group by\n",
    "filt = df['Country'] == 'United States'\n",
    "df.log[filt]['SocialMedia'].value_counts()              # 国家是 United States，SocialMedia 这列的不同值（WhatsApp, YouTube, LinkedIn...）的count\n",
    "\n",
    "country_grp = df.groupby(['Country'])                   # 返回值是一个 DataFrameGroupBy object\n",
    "\"\"\"\n",
    "<pandas.core.groupby.generic.DataFrameGroupBy object at 0x0000014A410881C0>\n",
    "\"\"\"\n",
    "country_grp.get_group('United States')                  # 取 Country 列，值为 United States 的行们\n",
    "country_grp['SocialMedia'].value_counts()               # 返回值：第一列是country，第二列是SocialMedia，第三列是count。前两列都是index\n",
    "\"\"\"\n",
    "Country      SocialMedia             \n",
    "Afghanistan  Facebook                    15\n",
    "             YouTube                      9\n",
    "             I don't use social media     6\n",
    "             WhatsApp                     4\n",
    "             Instagram                    1\n",
    "                                         ..\n",
    "Zimbabwe     Facebook                     3\n",
    "             YouTube                      3\n",
    "             Instagram                    2\n",
    "             LinkedIn                     2\n",
    "             Reddit                       1\n",
    "Name: SocialMedia, Length: 1220, dtype: int64\n",
    "\"\"\"\n",
    "country_grp['SocialMedia'].value_counts().loc('United States')      # 国家是 United States，SocialMedia 这列的不同值（WhatsApp, YouTube, LinkedIn...）的count. 与filter中一模一样的结果\n",
    "country_grp['ConvertedComp'].median().loc('United States')          # 每个国家收入中位数。.loc('United States') 美国的收入中位数\n",
    "country_grp['ConvertedComp'].agg(['median', 'mean'])                # 返回值是一个df，index是country的值。包含两列median + mean\n",
    "# ------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "filt = df['Country'] == 'India'\n",
    "df.loc[filt]['LanguageWorkedWith'].str.contains('Python').sum()     # 印度，使用python的行数总和\n",
    "\n",
    "country_grp['LanguageWorkedWith'].apply(lambda x: x.str.contains('Python').sum())\n",
    "# ------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "country_respondents = df['Country'].value_counts()                                                              # 返回值是每个国家的行数\n",
    "country_uses_python = country_grp['LanguageWorkedWith'].apply(lambda x: x.str.contains('Python').sum())         # 返回值是每个国家，使用python的行数     \n",
    "python_df = pd.concat([country_respondents, country_uses_python], axis='columns', sort=False)                   \n",
    "\"\"\"\n",
    "python_df:\n",
    "\t                Country\tLanguageWorkedWith\n",
    "United States\t    20949\t10083\n",
    "India\t            9061\t3105\n",
    "Germany\t            5866\t2451\n",
    "United Kingdom\t    5737\t2384\n",
    "Canada\t            3395\t1558\n",
    "...\t...\t...\n",
    "Tonga\t            1\t0\n",
    "Timor-Leste\t        1\t1\n",
    "North Korea \t    1\t0\n",
    "Brunei Darussalam\t1\t0\n",
    "Chad\t            1\t0\n",
    "\"\"\"      \n",
    "\n",
    "python_df.rename(columns={'Country': 'NumRespondents', 'LanguageWorkedWith': 'NumKnowsPython'})\n",
    "python_df['PctKnowsPython'] = (python_df['NumKnowsPython'] / python_df['NumRespondents']) * 100\n",
    "python_df.log['Japan']\n",
    "\"\"\"\n",
    "python_df.log['Japan']:\n",
    "NumRespondents      391.000\n",
    "NumKnowsPython      182.000\n",
    "PctKnowsPython      46.547\n",
    "Name: Japan, dtype: float64\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcffc6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. Cleaning Data - Casting Datatypes and Handling Missing Values - 1\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "people = {\n",
    "    \"first\": [\"Corey\", 'Jane', 'John', 'Adam', np.nan, None, 'NA'],\n",
    "    \"last\": [\"Schafer\", 'Doe', 'Doe', 'Doe', np.nan, np.nan, 'Missing'],\n",
    "    \"email\":[\"CoreyMSchafer@gmail.com\", 'JaneDoe@email.com', 'JohnDeo@email.com', None, np.nan, 'Anonumous@email.com', 'NA'],\n",
    "    'age': ['33', '55', '63', '36', None, None, 'Missing'],\n",
    "}\n",
    "\n",
    "\n",
    "df = pd.DataFrame(people)\n",
    "\n",
    "# -------------------------------------------------------------------------------------------------------\n",
    "df.dropna()                                                         # 任何有 np.nan / None 的值都会被去掉, np.nan: not a number value\n",
    "df.dropna(axis='index', how='any')                                  # 这是默认参数值\n",
    "df.dropna(axis='column', how='all')             \n",
    "df.dropna(axis='index', how='any', subset=['email'])                # 只考察email这列的空值\n",
    "# -------------------------------------------------------------------------------------------------------\n",
    "df.replace('NA', np.nan, inplace=True)\n",
    "df.replace('Missing', np.nan, inplace=True)\n",
    "# -------------------------------------------------------------------------------------------------------\n",
    "df.isna()                   # 返回一个 df，包括 true / false 值\n",
    "df.fillna('MISSING')        # 将空值填入 \"MISSING\"\n",
    "# -------------------------------------------------------------------------------------------------------\n",
    "df.dtypes\n",
    "\"\"\"\n",
    "first       object\n",
    "last        object\n",
    "email       object\n",
    "age         object\n",
    "dtype: object\n",
    "\"\"\"\n",
    "df['age'].mean()        # 将会报错，因为是object/string\n",
    "df['age'] = df['age'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c96890",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. Cleaning Data - Casting Datatypes and Handling Missing Values - 2\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "na_vals = ['NA', 'Missing']             # 将值为 'NA' / 'Missing' 的cell改成 np.nan\n",
    "df = pd.read_csv('data/survey_results_public.csv', index_col='Respondent', na_values=na_vals)\n",
    "schema_df = pd.read_csv('data/survey_results_schema.csv', index_col='Column', na_values=na_vals)\n",
    "\n",
    "# -------------------------------------------------------------------------------------------------------\n",
    "pd.set_option('display.max_columns', 85)\n",
    "pd.set_option('display.max_rows', 85)\n",
    "df.head()\n",
    "# -------------------------------------------------------------------------------------------------------\n",
    "df['YearsCode'].head(10)\n",
    "\"\"\"\n",
    "Respondent\n",
    "1   4\n",
    "2   NaN\n",
    "3   3\n",
    "4   3\n",
    "5   16 \n",
    "6   13\n",
    "7   6\n",
    "8   8\n",
    "9   12\n",
    "10  12\n",
    "Name: YearsCode, dtype: object\n",
    "\"\"\"\n",
    "df['YearsCode'].mean()                              # ERROR: can only concatenate str (not \"int\") to str, 这就是 string 不能计算 mean 的错误\n",
    "df['YearsCode'] = df['YearsCode'].astype(float)     # ERROR: could not convert string to float: 'Less than 1 year'\n",
    "df['YearsCode'].unique()\n",
    "\"\"\"\n",
    "array(['4', nan, '3', ......, 'Less than 1 year', 'More than 50 years', ......], dytpe=object)\n",
    "\"\"\"\n",
    "# -------------------------------------------------------------------------------------------------------\n",
    "df['YearsCode'].replace('Less than 1 year', 0, inplace=True)\n",
    "df['YearsCode'].replace('More than 50 years', 51, inplace=True)\n",
    "df['YearsCode'] = df['YearsCode'].astype(float)\n",
    "df['YearsCode'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaed9135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. Working with Dates and Time Series Data\n",
    "\n",
    "df = pd.read_csv('ETH_1h.csv')\n",
    "df.head()\n",
    "\n",
    "# -------------------------------------------------------------------------------------------------------\n",
    "df.loc[0, 'Date']                           # 2020-03-13 08-PM\n",
    "df.loc[0, 'Date'].day_name()                # week day of this date. ERROR: str object has no attribute 'day_name'\n",
    "df['Date'] = pd.to_datetime(df['Date'])     # ERROR: unknown string format: 2020-03-13 08-PM\n",
    "df['Date'] = pd.to_datetime(df['Date'], format='%Y-%m-%d %I-%p')            # I - 12 hour clock, p - AM/PM, 将 08-PM 转换为了20：00：00\n",
    "df.loc[0, 'Date'].day_name()                # Friday\n",
    "# -------------------------------------------------------------------------------------------------------\n",
    "d_parser = lambda x: pd.datetime.strptime(x, '%Y-%m-%d %I-%p')\n",
    "df = pd.read_csv('ETH_1h.csv', parse_dates=['Date'], date_parser=d_parser)\n",
    "df.head()\n",
    "df['Date'].dt.day_name()\n",
    "# -------------------------------------------------------------------------------------------------------\n",
    "df['Date'].min()                # Timestamp('2017-07-01 11:00:00')\n",
    "df['Date'].max()                \n",
    "df['Date'].max() - df['Date'].min()  # TimeDelta('986 days 09:00:00')\n",
    "# -------------------------------------------------------------------------------------------------------\n",
    "filt = (df['Date'] >= '2020')\n",
    "df.loc[filt]\n",
    "filt = (df['Date'] >= pd.to_datetime('2019-01-01')) & (df['Date'] < pd.to_datetime('2020-01-01'))\n",
    "df.loc[filt]\n",
    "# -------------------------------------------------------------------------------------------------------\n",
    "df.set_index('Date', inplace=True)\n",
    "df['2019']                          # 就可以得到 'Date' 列是 2019 年的那些行\n",
    "df['2020-01': '2020-02']            # 就可以得到 'Date' 列是 2020-01 直到 2020-02 的那些行\n",
    "# -------------------------------------------------------------------------------------------------------\n",
    "df['2020-01-01']['High'].max()\n",
    "highs = df['High'].resample('D').max()      # 找出每天(D) 'High' 这列的最大值\n",
    "highs['2020-01-01']                         # 结果与 df['2020-01-01']['High'].max() 相同\n",
    "%matplotlib inline\n",
    "highs.plot()                                # 会做个折线图\n",
    "df.resmaple('W').mean()                     # 每周,每个列,的平均值\n",
    "df.resmaple('W').agg({'Close': 'mean', 'High': 'max', 'Low':'min', 'Volumn': 'sum'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109e8169",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. Reading/Writing Data to Different Sources - Excel, JSON, SQL, Etc\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "df = pd.read_csv('data/survey_results_public.csv', index_col='Respondent')\n",
    "schema_df = pd.read_csv('data/survey_results_schema.csv', index_col='Column')\n",
    "\n",
    "pd.set_option('display.max_columns', 85)\n",
    "pd.set_option('display.max_rows', 85)\n",
    "df.head()\n",
    "\n",
    "filt = (df['Country'] == 'India')\n",
    "india_df = df.loc[filt]\n",
    "india_df\n",
    "\n",
    "india_df.to_csv('data/modified.csv')\n",
    "india_df.to_csv('data/modified.tsv', sep='\\t')          # 利用tab分隔,而非默认的逗号\n",
    "# -------------------------------------------------------------------------------------------------------\n",
    "\"\"\" pip install xlwt openpyxl  xlrd \"\"\"\n",
    "india_df.to_excel('data/modified.xlsx')\n",
    "test = pd.read_excel('data/modified.xlsx', index_col = 'Respondent')\n",
    "test.head()\n",
    "# -------------------------------------------------------------------------------------------------------\n",
    "india_df.to_json('data/modified.json')\n",
    "india_df.to_json('data/modified.json', orient='records', lines=True)         # orient='records', list like. lines=True, make each of these a new line\n",
    "test = pd.read_json('data/modified.json', orient='records', lines=True)\n",
    "test.head()\n",
    "# -------------------------------------------------------------------------------------------------------\n",
    "\"\"\" pip install SQLAlchemy psycopg2-binary \"\"\"\n",
    "from sqlalchemy import create_engine\n",
    "import psycopg2\n",
    "\n",
    "engine = create_engine('postgresqp://dbuser:dbpass@localhost:5432/sample_db')\n",
    "india_df.to_sql('sample_table', engine)\n",
    "\n",
    "sql_df = pd.read_sql('sammple_table', engine, index_col='Respondent')\n",
    "sql_df.head()\n",
    "\n",
    "sql_df = pd.read_sql_query('select * from sample_table', engine, index_col='Respondent')\n",
    "sql_df.head()\n",
    "\n",
    "posts_df = pd.read_json('https://raw.sjdkfjslkfj/sjdfkjkl.json')\n",
    "posts_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "vscode": {
   "interpreter": {
    "hash": "7b9bf3d753fefe854781e52229fcc2b6d37fd5cec0eed166290fc2ac2cd3389d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
